{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Smart (Ai) Pothole Detector (Powered by \"Tensorflow/TensorRT\" on \"Google Colab\" and or \"Jetson Nano\").ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thenisvan/AI-Pothole-Detection-Using-YOLO/blob/master/Smart_(Ai)_Pothole_Detector_(Powered_by_%22Tensorflow_TensorRT%22_on_%22Google_Colab%22_and_or_%22Jetson_Nano%22).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwpja-Up3TU6"
      },
      "source": [
        "#Smart (Ai) Pothole Detector (Powered by \"Tensorflow/TensorRT\" on \"Google Colab\" and or \"Jetson Nano\" via a Convolutional Artificial Neural Network)\n",
        "\n",
        "\n",
        "# Author\n",
        "Jordan Bennett (**folioverse.appspot.com**).\n",
        "\n",
        "Thanks Google, TensorRt creators, thanks jhasuman, for his [desktop-version yolo-v2 based pothole detector](https://github.com/JordanMicahBennett/potholes-detection).\n",
        "\n",
        "*   This project by Jordan essentially converts jhasuman's neural network based desktop pothole detector above (fp32 aka single precision floating point/32 bits), to jetson nano neural network based pothole detector (fp16 half precision floating point 16 bits). (**Purpose of which is to add the jetson nano with the trained half precision pothole detector to my car, and perhaps offer to others for sale?**)\n",
        "\n",
        "\n",
        "\n",
        "# Success\n",
        "There were lots of head scratching moments, but the tensorRT/jetson nano-mini computer version works fine, with seemingly similar accuracy to full Desktop version, as seen [in Part B/4 Prediction](https://colab.research.google.com/drive/1kGV8DXJ7RwQtCDmd2QOc80Bll5n24Ftp#scrollTo=ZrHyjN_Cvk4Z&line=14&uniqifier=1).\n",
        "\n",
        "\n",
        "# Background \n",
        "This Google Colab code is separate from the final product code I prepared for the jetson nano, although the nano code uses some of this colab code. \n",
        "\n",
        "The jetson nano is a portable device, and hence this may be attached to a vehicle to do pothole detection, based on [convolutional neural networks](https://en.wikipedia.org/wiki/Convolutional_neural_network).\n",
        "\n",
        "# I. Instructions to run on Jetson nano neural computer\n",
        "1. Follow these instructions from [this Jetson Nano purchase and setup repository of mine](https://github.com/JordanMicahBennett/live_ai_object-detection-on-tiny-jetson-neural-nano-computer).\n",
        "\n",
        "\n",
        "2. Download \"[optimized trt_pothole_graph.pb graph](https://drive.google.com/file/d/1b9XgpXeWBay6GE2bnLSqlLSXDEFfUCZd/view?usp=sharing)\" aka saved pothole detection neural network.\n",
        "\n",
        "\n",
        "3. Download \"[Ai Vehicle Pothole Detector (Powered by Jetson Nano Neural Computer)__________________.zip](https://drive.google.com/open?id=1wnO4IFE33CAppRkr0RI5TSgqU99J-wHO)\".\n",
        "\n",
        "4. Copy .pb file from (2) to extracted directory of folder from (3) above.\n",
        "\n",
        "5. Run jetson_nano_pothole_detector from (3), and see what jetson nano returns from the saved neural network.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# II. Alternatively, Instructions/steps to run on [Google Colab](https://colab.research.google.com/drive/1kGV8DXJ7RwQtCDmd2QOc80Bll5n24Ftp#scrollTo=Hwpja-Up3TU6&line=20&uniqifier=1) in your browser, if you don't have a jetson nano device.\n",
        "\n",
        "\n",
        "The first 4 steps below were added by Jordan, and other steps added/modified to align with custom pothole model, based on this [original blog/colab code](https://www.dlology.com/blog/how-to-run-keras-model-on-jetson-nano/).\n",
        "\n",
        "##Part A: Prequisites\n",
        "0. [Connect to Jordan's Google drive to access saved neural network weights etc](https://colab.research.google.com/drive/1kGV8DXJ7RwQtCDmd2QOc80Bll5n24Ftp#scrollTo=ma8JcJc9pzmH&line=11&uniqifier=1)\n",
        "\n",
        "1. [Backend](https://colab.research.google.com/drive/1kGV8DXJ7RwQtCDmd2QOc80Bll5n24Ftp#scrollTo=qWBtb7Xin-zG&line=25&uniqifier=1)\n",
        "\n",
        "2. [Utils](https://colab.research.google.com/drive/1kGV8DXJ7RwQtCDmd2QOc80Bll5n24Ftp#scrollTo=EGRugrAUnNrv&line=7&uniqifier=1)\n",
        "\n",
        "3. [Frontend](https://colab.research.google.com/drive/1kGV8DXJ7RwQtCDmd2QOc80Bll5n24Ftp#scrollTo=lOgZDSUYnDQC&line=11&uniqifier=1)\n",
        "\n",
        "\n",
        "##Part B: TensorRT Conversion & Usage steps\n",
        "\n",
        "1. [Frozen graph creation](https://colab.research.google.com/drive/1kGV8DXJ7RwQtCDmd2QOc80Bll5n24Ftp#scrollTo=CgVxdMRCmFcn&line=10&uniqifier=1)\n",
        "\n",
        "2. [TensorRT graph conversion of frozen graph](https://colab.research.google.com/drive/1kGV8DXJ7RwQtCDmd2QOc80Bll5n24Ftp#scrollTo=fWygvIyctpeI&line=10&uniqifier=1)\n",
        "\n",
        "3. [Load tensor rt graph](https://colab.research.google.com/drive/1kGV8DXJ7RwQtCDmd2QOc80Bll5n24Ftp#scrollTo=L-Jx1Yq0uejv&line=4&uniqifier=1)\n",
        "\n",
        "4. [Use loaded tensor rt graph to make predictions](https://colab.research.google.com/drive/1kGV8DXJ7RwQtCDmd2QOc80Bll5n24Ftp#scrollTo=ZrHyjN_Cvk4Z&line=14&uniqifier=1)\n",
        "\n",
        "\n",
        "## Part C: Quick Test Order (I use the order below to run files to run pothole prediction test, based on how I organized all files in this google colab project and on my google drive)\n",
        "\n",
        "*   [Part A  (0)](https://colab.research.google.com/drive/1kGV8DXJ7RwQtCDmd2QOc80Bll5n24Ftp#scrollTo=ma8JcJc9pzmH&line=11&uniqifier=1) ----> [Part B (2b)](https://colab.research.google.com/drive/1kGV8DXJ7RwQtCDmd2QOc80Bll5n24Ftp#scrollTo=kGqN3UXquW-m) ----> [Part B (3a)](https://colab.research.google.com/drive/1kGV8DXJ7RwQtCDmd2QOc80Bll5n24Ftp#scrollTo=L-Jx1Yq0uejv&line=4&uniqifier=1) ----> [Part B (3b)](https://colab.research.google.com/drive/1kGV8DXJ7RwQtCDmd2QOc80Bll5n24Ftp#scrollTo=Azhh5OA2vI72&line=7&uniqifier=1) ----> [Part B (4)]()\n",
        "\n",
        "\n",
        "#Performance comparison, between Desktop and TensorRT/Nano version:\n",
        "\n",
        "1. See screenshot of fps count using TensorRT/Nano neural network pothole detector: https://drive.google.com/file/d/1LoWDsX75ehQ7HwcL1asz_EnRTZfHvrEs/view?usp=sharing\n",
        "\n",
        "2. See screenshot of fps count using Desktop neural network pothole detector: \n",
        "https://drive.google.com/file/d/1xnp304UfWpSWSLvqLvGDNGTHPFyBh9FN/view?usp=sharing \n",
        "\n",
        "\n",
        "\n",
        "# Future work:\n",
        "\n",
        "1. Find out how costly it would be to incoroprate a [dark to bright neural network](https://github.com/cchen156/Learning-to-See-in-the-Dark) converter, to enable pothole detection at night.\n",
        "\n",
        "2. Live speedbump detection. (Especially those haphazzardly painted ones that are painted black like road)\n",
        "\n",
        "3. Other obstacle detection, that may be too thin for car sensors to pick up.\n",
        "\n",
        "\n",
        "# Youtube clip of Pothole TensorRT Ai in action on Google Colab\n",
        "\n",
        "https://www.youtube.com/watch?v=MgsK3UrYEOI\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma8JcJc9pzmH"
      },
      "source": [
        "\n",
        "###################\n",
        "#Part A/0. Connect to Google drive to access saved neural nwtwork wrights etc\n",
        "###################\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive \n",
        "from google.colab import auth \n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()                       \n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWBtb7Xin-zG"
      },
      "source": [
        "\n",
        "###################\n",
        "#Part A/1. backend.py from https://github.com/jhasuman/potholes-detection\n",
        "###################\n",
        "\n",
        "jordan_drive_full_yolo_backend_id = '1LjcG4pA8mdF0UidPLH2Ov-qiATT0Map8';\n",
        "file_obj_full_yolo_backend = drive.CreateFile({'id': jordan_drive_full_yolo_backend_id})                       \n",
        "file_obj_full_yolo_backend.GetContentFile ( \"full_yolo_backend.h5\" )\n",
        "\n",
        "\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.applications import InceptionV3\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "\n",
        "FULL_YOLO_BACKEND_PATH  = \"full_yolo_backend.h5\"   # should be hosted on a server\n",
        "TINY_YOLO_BACKEND_PATH  = \"tiny_yolo_backend.h5\"   # should be hosted on a server\n",
        "SQUEEZENET_BACKEND_PATH = \"squeezenet_backend.h5\"  # should be hosted on a server\n",
        "MOBILENET_BACKEND_PATH  = \"mobilenet_backend.h5\"   # should be hosted on a server\n",
        "INCEPTION3_BACKEND_PATH = \"inception_backend.h5\"   # should be hosted on a server\n",
        "VGG16_BACKEND_PATH      = \"vgg16_backend.h5\"       # should be hosted on a server\n",
        "RESNET50_BACKEND_PATH   = \"resnet50_backend.h5\"    # should be hosted on a server\n",
        "\n",
        "class BaseFeatureExtractor(object):\n",
        "    \"\"\"docstring for ClassName\"\"\"\n",
        "\n",
        "    # to be defined in each subclass\n",
        "    def __init__(self, input_size):\n",
        "        raise NotImplementedError(\"error message\")\n",
        "\n",
        "    # to be defined in each subclass\n",
        "    def normalize(self, image):\n",
        "        raise NotImplementedError(\"error message\")       \n",
        "\n",
        "    def get_output_shape(self):\n",
        "        return self.feature_extractor.get_output_shape_at(-1)[1:3]\n",
        "\n",
        "    def extract(self, input_image):\n",
        "        return self.feature_extractor(input_image)\n",
        "\n",
        "class FullYoloFeature(BaseFeatureExtractor):\n",
        "    \"\"\"docstring for ClassName\"\"\"\n",
        "    def __init__(self, input_size):\n",
        "        input_image = Input(shape=(input_size, input_size, 3))\n",
        "\n",
        "        # the function to implement the orgnization layer (thanks to github.com/allanzelener/YAD2K)\n",
        "        def space_to_depth_x2(x):\n",
        "            return tf.space_to_depth(x, block_size=2)\n",
        "\n",
        "        # Layer 1\n",
        "        x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
        "        x = BatchNormalization(name='norm_1')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "        # Layer 2\n",
        "        x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_2')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "        # Layer 3\n",
        "        x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_3')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 4\n",
        "        x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_4')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 5\n",
        "        x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_5')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "        # Layer 6\n",
        "        x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_6')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 7\n",
        "        x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_7')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 8\n",
        "        x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_8')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "        # Layer 9\n",
        "        x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_9')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 10\n",
        "        x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_10')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 11\n",
        "        x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_11')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 12\n",
        "        x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_12')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 13\n",
        "        x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_13')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        skip_connection = x\n",
        "\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "        # Layer 14\n",
        "        x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_14')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 15\n",
        "        x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_15')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 16\n",
        "        x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_16')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 17\n",
        "        x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_17')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 18\n",
        "        x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_18')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 19\n",
        "        x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_19')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 20\n",
        "        x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_20')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        # Layer 21\n",
        "        skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
        "        skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
        "        skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
        "        skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
        "\n",
        "        x = concatenate([skip_connection, x])\n",
        "\n",
        "        # Layer 22\n",
        "        x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_22')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        self.feature_extractor = Model(input_image, x)  \n",
        "        self.feature_extractor.load_weights(FULL_YOLO_BACKEND_PATH,by_name=True)\n",
        "\n",
        "    def normalize(self, image):\n",
        "        return image / 255.\n",
        "\n",
        "class TinyYoloFeature(BaseFeatureExtractor):\n",
        "    \"\"\"docstring for ClassName\"\"\"\n",
        "    def __init__(self, input_size):\n",
        "        input_image = Input(shape=(input_size, input_size, 3))\n",
        "\n",
        "        # Layer 1\n",
        "        x = Conv2D(16, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
        "        x = BatchNormalization(name='norm_1')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "        # Layer 2 - 5\n",
        "        for i in range(0,4):\n",
        "            x = Conv2D(32*(2**i), (3,3), strides=(1,1), padding='same', name='conv_' + str(i+2), use_bias=False)(x)\n",
        "            x = BatchNormalization(name='norm_' + str(i+2))(x)\n",
        "            x = LeakyReLU(alpha=0.1)(x)\n",
        "            x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "        # Layer 6\n",
        "        x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
        "        x = BatchNormalization(name='norm_6')(x)\n",
        "        x = LeakyReLU(alpha=0.1)(x)\n",
        "        x = MaxPooling2D(pool_size=(2, 2), strides=(1,1), padding='same')(x)\n",
        "\n",
        "        # Layer 7 - 8\n",
        "        for i in range(0,2):\n",
        "            x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_' + str(i+7), use_bias=False)(x)\n",
        "            x = BatchNormalization(name='norm_' + str(i+7))(x)\n",
        "            x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "        self.feature_extractor = Model(input_image, x)  \n",
        "        self.feature_extractor.load_weights(TINY_YOLO_BACKEND_PATH)\n",
        "\n",
        "    def normalize(self, image):\n",
        "        return image / 255.\n",
        "\n",
        "class MobileNetFeature(BaseFeatureExtractor):\n",
        "    \"\"\"docstring for ClassName\"\"\"\n",
        "    def __init__(self, input_size):\n",
        "        input_image = Input(shape=(input_size, input_size, 3))\n",
        "\n",
        "        mobilenet = MobileNet(input_shape=(224,224,3), include_top=False)\n",
        "        mobilenet.load_weights(MOBILENET_BACKEND_PATH)\n",
        "\n",
        "        x = mobilenet(input_image)\n",
        "\n",
        "        self.feature_extractor = Model(input_image, x)  \n",
        "\n",
        "    def normalize(self, image):\n",
        "        image = image / 255.\n",
        "        image = image - 0.5\n",
        "        image = image * 2.\n",
        "\n",
        "        return image\t\t\n",
        "\n",
        "class SqueezeNetFeature(BaseFeatureExtractor):\n",
        "    \"\"\"docstring for ClassName\"\"\"\n",
        "    def __init__(self, input_size):\n",
        "\n",
        "        # define some auxiliary variables and the fire module\n",
        "        sq1x1  = \"squeeze1x1\"\n",
        "        exp1x1 = \"expand1x1\"\n",
        "        exp3x3 = \"expand3x3\"\n",
        "        relu   = \"relu_\"\n",
        "\n",
        "        def fire_module(x, fire_id, squeeze=16, expand=64):\n",
        "            s_id = 'fire' + str(fire_id) + '/'\n",
        "\n",
        "            x     = Conv2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
        "            x     = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
        "\n",
        "            left  = Conv2D(expand,  (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
        "            left  = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
        "\n",
        "            right = Conv2D(expand,  (3, 3), padding='same',  name=s_id + exp3x3)(x)\n",
        "            right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
        "\n",
        "            x = concatenate([left, right], axis=3, name=s_id + 'concat')\n",
        "\n",
        "            return x\n",
        "\n",
        "        # define the model of SqueezeNet\n",
        "        input_image = Input(shape=(input_size, input_size, 3))\n",
        "\n",
        "        x = Conv2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(input_image)\n",
        "        x = Activation('relu', name='relu_conv1')(x)\n",
        "        x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
        "\n",
        "        x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
        "        x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
        "        x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
        "\n",
        "        x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
        "        x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
        "        x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
        "\n",
        "        x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
        "        x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
        "        x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
        "        x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
        "\n",
        "        self.feature_extractor = Model(input_image, x)  \n",
        "        self.feature_extractor.load_weights(SQUEEZENET_BACKEND_PATH)\n",
        "\n",
        "    def normalize(self, image):\n",
        "        image = image[..., ::-1]\n",
        "        image = image.astype('float')\n",
        "\n",
        "        image[..., 0] -= 103.939\n",
        "        image[..., 1] -= 116.779\n",
        "        image[..., 2] -= 123.68\n",
        "\n",
        "        return image    \n",
        "\n",
        "class Inception3Feature(BaseFeatureExtractor):\n",
        "    \"\"\"docstring for ClassName\"\"\"\n",
        "    def __init__(self, input_size):\n",
        "        input_image = Input(shape=(input_size, input_size, 3))\n",
        "\n",
        "        inception = InceptionV3(input_shape=(input_size,input_size,3), include_top=False)\n",
        "        inception.load_weights(INCEPTION3_BACKEND_PATH)\n",
        "\n",
        "        x = inception(input_image)\n",
        "\n",
        "        self.feature_extractor = Model(input_image, x)  \n",
        "\n",
        "    def normalize(self, image):\n",
        "        image = image / 255.\n",
        "        image = image - 0.5\n",
        "        image = image * 2.\n",
        "\n",
        "        return image\n",
        "\n",
        "class VGG16Feature(BaseFeatureExtractor):\n",
        "    \"\"\"docstring for ClassName\"\"\"\n",
        "    def __init__(self, input_size):\n",
        "        vgg16 = VGG16(input_shape=(input_size, input_size, 3), include_top=False)\n",
        "        #vgg16.load_weights(VGG16_BACKEND_PATH)\n",
        "\n",
        "        self.feature_extractor = vgg16\n",
        "\n",
        "    def normalize(self, image):\n",
        "        image = image[..., ::-1]\n",
        "        image = image.astype('float')\n",
        "\n",
        "        image[..., 0] -= 103.939\n",
        "        image[..., 1] -= 116.779\n",
        "        image[..., 2] -= 123.68\n",
        "\n",
        "        return image \n",
        "\n",
        "class ResNet50Feature(BaseFeatureExtractor):\n",
        "    \"\"\"docstring for ClassName\"\"\"\n",
        "    def __init__(self, input_size):\n",
        "        resnet50 = ResNet50(input_shape=(input_size, input_size, 3), include_top=False)\n",
        "        resnet50.layers.pop() # remove the average pooling layer\n",
        "        #resnet50.load_weights(RESNET50_BACKEND_PATH)\n",
        "\n",
        "        self.feature_extractor = Model(resnet50.layers[0].input, resnet50.layers[-1].output)\n",
        "\n",
        "    def normalize(self, image):\n",
        "        image = image[..., ::-1]\n",
        "        image = image.astype('float')\n",
        "\n",
        "        image[..., 0] -= 103.939\n",
        "        image[..., 1] -= 116.779\n",
        "        image[..., 2] -= 123.68\n",
        "\n",
        "        return image \n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGRugrAUnNrv"
      },
      "source": [
        "###################\n",
        "#Part A/2. utils.py from https://github.com/jhasuman/potholes-detection\n",
        "###################\n",
        "import numpy as np\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import tensorflow as tf\n",
        "import copy\n",
        "import cv2\n",
        "\n",
        "class BoundBox:\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, c = None, classes = None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "        \n",
        "        self.c     = c\n",
        "        self.classes = classes\n",
        "\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "\n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "        \n",
        "        return self.label\n",
        "    \n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "            \n",
        "        return self.score\n",
        "\n",
        "class WeightReader:\n",
        "    def __init__(self, weight_file):\n",
        "        self.offset = 4\n",
        "        self.all_weights = np.fromfile(weight_file, dtype='float32')\n",
        "        \n",
        "    def read_bytes(self, size):\n",
        "        self.offset = self.offset + size\n",
        "        return self.all_weights[self.offset-size:self.offset]\n",
        "    \n",
        "    def reset(self):\n",
        "        self.offset = 4\n",
        "\n",
        "def bbox_iou(box1, box2):\n",
        "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])  \n",
        "    \n",
        "    intersect = intersect_w * intersect_h\n",
        "\n",
        "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "    \n",
        "    union = w1*h1 + w2*h2 - intersect\n",
        "    \n",
        "    return float(intersect) / union\n",
        "\n",
        "def draw_boxes(image, boxes, labels):\n",
        "    image_h, image_w, _ = image.shape\n",
        "\n",
        "    for box in boxes:\n",
        "        xmin = int(box.xmin*image_w)\n",
        "        ymin = int(box.ymin*image_h)\n",
        "        xmax = int(box.xmax*image_w)\n",
        "        ymax = int(box.ymax*image_h)\n",
        "\n",
        "        cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (0,255,0), 3)\n",
        "        cv2.putText(image, \n",
        "                    labels[box.get_label()] + ' ' + str(box.get_score()), \n",
        "                    (xmin, ymin - 13), \n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                    1e-3 * image_h, \n",
        "                    (0,255,0), 2)\n",
        "        \n",
        "    return image          \n",
        "        \n",
        "def decode_netout(netout, anchors, nb_class, obj_threshold=0.3, nms_threshold=0.3):\n",
        "    grid_h, grid_w, nb_box = netout.shape[:3]\n",
        "\n",
        "    boxes = []\n",
        "    \n",
        "    # decode the output by the network\n",
        "    netout[..., 4]  = _sigmoid(netout[..., 4])\n",
        "    netout[..., 5:] = netout[..., 4][..., np.newaxis] * _softmax(netout[..., 5:])\n",
        "    netout[..., 5:] *= netout[..., 5:] > obj_threshold\n",
        "    \n",
        "    for row in range(grid_h):\n",
        "        for col in range(grid_w):\n",
        "            for b in range(nb_box):\n",
        "                # from 4th element onwards are confidence and class classes\n",
        "                classes = netout[row,col,b,5:]\n",
        "                \n",
        "                if np.sum(classes) > 0:\n",
        "                    # first 4 elements are x, y, w, and h\n",
        "                    x, y, w, h = netout[row,col,b,:4]\n",
        "\n",
        "                    x = (col + _sigmoid(x)) / grid_w # center position, unit: image width\n",
        "                    y = (row + _sigmoid(y)) / grid_h # center position, unit: image height\n",
        "                    w = anchors[2 * b + 0] * np.exp(w) / grid_w # unit: image width\n",
        "                    h = anchors[2 * b + 1] * np.exp(h) / grid_h # unit: image height\n",
        "                    confidence = netout[row,col,b,4]\n",
        "                    \n",
        "                    box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, confidence, classes)\n",
        "                    \n",
        "                    boxes.append(box)\n",
        "\n",
        "    # suppress non-maximal boxes\n",
        "    for c in range(nb_class):\n",
        "        sorted_indices = list(reversed(np.argsort([box.classes[c] for box in boxes])))\n",
        "\n",
        "        for i in range(len(sorted_indices)):\n",
        "            index_i = sorted_indices[i]\n",
        "            \n",
        "            if boxes[index_i].classes[c] == 0: \n",
        "                continue\n",
        "            else:\n",
        "                for j in range(i+1, len(sorted_indices)):\n",
        "                    index_j = sorted_indices[j]\n",
        "                    \n",
        "                    if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_threshold:\n",
        "                        boxes[index_j].classes[c] = 0\n",
        "                        \n",
        "    # remove the boxes which are less likely than a obj_threshold\n",
        "    boxes = [box for box in boxes if box.get_score() > obj_threshold]\n",
        "    \n",
        "    return boxes    \n",
        "\n",
        "def compute_overlap(a, b):\n",
        "    \"\"\"\n",
        "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
        "    Parameters\n",
        "    ----------\n",
        "    a: (N, 4) ndarray of float\n",
        "    b: (K, 4) ndarray of float\n",
        "    Returns\n",
        "    -------\n",
        "    overlaps: (N, K) ndarray of overlap between boxes and query_boxes\n",
        "    \"\"\"\n",
        "    area = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n",
        "\n",
        "    iw = np.minimum(np.expand_dims(a[:, 2], axis=1), b[:, 2]) - np.maximum(np.expand_dims(a[:, 0], 1), b[:, 0])\n",
        "    ih = np.minimum(np.expand_dims(a[:, 3], axis=1), b[:, 3]) - np.maximum(np.expand_dims(a[:, 1], 1), b[:, 1])\n",
        "\n",
        "    iw = np.maximum(iw, 0)\n",
        "    ih = np.maximum(ih, 0)\n",
        "\n",
        "    ua = np.expand_dims((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), axis=1) + area - iw * ih\n",
        "\n",
        "    ua = np.maximum(ua, np.finfo(float).eps)\n",
        "\n",
        "    intersection = iw * ih\n",
        "\n",
        "    return intersection / ua  \n",
        "    \n",
        "def compute_ap(recall, precision):\n",
        "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
        "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
        "\n",
        "    # Arguments\n",
        "        recall:    The recall curve (list).\n",
        "        precision: The precision curve (list).\n",
        "    # Returns\n",
        "        The average precision as computed in py-faster-rcnn.\n",
        "    \"\"\"\n",
        "    # correct AP calculation\n",
        "    # first append sentinel values at the end\n",
        "    mrec = np.concatenate(([0.], recall, [1.]))\n",
        "    mpre = np.concatenate(([0.], precision, [0.]))\n",
        "\n",
        "    # compute the precision envelope\n",
        "    for i in range(mpre.size - 1, 0, -1):\n",
        "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
        "\n",
        "    # to calculate area under PR curve, look for points\n",
        "    # where X axis (recall) changes value\n",
        "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
        "\n",
        "    # and sum (\\Delta recall) * prec\n",
        "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
        "    return ap      \n",
        "        \n",
        "def _interval_overlap(interval_a, interval_b):\n",
        "    x1, x2 = interval_a\n",
        "    x3, x4 = interval_b\n",
        "\n",
        "    if x3 < x1:\n",
        "        if x4 < x1:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x1\n",
        "    else:\n",
        "        if x2 < x3:\n",
        "             return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x3          \n",
        "\n",
        "def _sigmoid(x):\n",
        "    return 1. / (1. + np.exp(-x))\n",
        "\n",
        "def _softmax(x, axis=-1, t=-100.):\n",
        "    x = x - np.max(x)\n",
        "    \n",
        "    if np.min(x) < t:\n",
        "        x = x/np.min(x)*t\n",
        "        \n",
        "    e_x = np.exp(x)\n",
        "    \n",
        "    return e_x / e_x.sum(axis, keepdims=True)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOgZDSUYnDQC"
      },
      "source": [
        "###################\n",
        "#Part A/3. frontend.py from https://github.com/jhasuman/potholes-detection\n",
        "###################\n",
        "from keras.models import Model\n",
        "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "\n",
        "class YOLO(object):\n",
        "    def __init__(self, backend,\n",
        "                       input_size, \n",
        "                       labels, \n",
        "                       max_box_per_image,\n",
        "                       anchors):\n",
        "\n",
        "        self.input_size = input_size\n",
        "        \n",
        "        self.labels   = list(labels)\n",
        "        self.nb_class = len(self.labels)\n",
        "        self.nb_box   = len(anchors)//2\n",
        "        self.class_wt = np.ones(self.nb_class, dtype='float32')\n",
        "        self.anchors  = anchors\n",
        "\n",
        "        self.max_box_per_image = max_box_per_image\n",
        "\n",
        "        ##########################\n",
        "        # Make the model\n",
        "        ##########################\n",
        "\n",
        "        # make the feature extractor layers\n",
        "        input_image     = Input(shape=(self.input_size, self.input_size, 3))\n",
        "        self.true_boxes = Input(shape=(1, 1, 1, max_box_per_image , 4))  \n",
        "\n",
        "        if backend == 'Inception3':\n",
        "            self.feature_extractor = Inception3Feature(self.input_size)  \n",
        "        elif backend == 'SqueezeNet':\n",
        "            self.feature_extractor = SqueezeNetFeature(self.input_size)        \n",
        "        elif backend == 'MobileNet':\n",
        "            self.feature_extractor = MobileNetFeature(self.input_size)\n",
        "        elif backend == 'Full Yolo':\n",
        "            self.feature_extractor = FullYoloFeature(self.input_size)\n",
        "        elif backend == 'Tiny Yolo':\n",
        "            self.feature_extractor = TinyYoloFeature(self.input_size)\n",
        "        elif backend == 'VGG16':\n",
        "            self.feature_extractor = VGG16Feature(self.input_size)\n",
        "        elif backend == 'ResNet50':\n",
        "            self.feature_extractor = ResNet50Feature(self.input_size)\n",
        "        else:\n",
        "            raise Exception('Architecture not supported! Only support Full Yolo, Tiny Yolo, MobileNet, SqueezeNet, VGG16, ResNet50, and Inception3 at the moment!')\n",
        "\n",
        "        print(self.feature_extractor.get_output_shape())    \n",
        "        self.grid_h, self.grid_w = self.feature_extractor.get_output_shape()        \n",
        "        features = self.feature_extractor.extract(input_image)            \n",
        "\n",
        "        # make the object detection layer\n",
        "        output = Conv2D(self.nb_box * (4 + 1 + self.nb_class), \n",
        "                        (1,1), strides=(1,1), \n",
        "                        padding='same', \n",
        "                        name='DetectionLayer', \n",
        "                        kernel_initializer='lecun_normal')(features)\n",
        "        output = Reshape((self.grid_h, self.grid_w, self.nb_box, 4 + 1 + self.nb_class))(output)\n",
        "        output = Lambda(lambda args: args[0])([output, self.true_boxes])\n",
        "\n",
        "        self.model = Model([input_image, self.true_boxes], output)\n",
        "\n",
        "        \n",
        "        # initialize the weights of the detection layer\n",
        "        layer = self.model.layers[-4]\n",
        "        weights = layer.get_weights()\n",
        "\n",
        "        new_kernel = np.random.normal(size=weights[0].shape)/(self.grid_h*self.grid_w)\n",
        "        new_bias   = np.random.normal(size=weights[1].shape)/(self.grid_h*self.grid_w)\n",
        "\n",
        "        layer.set_weights([new_kernel, new_bias])\n",
        "\n",
        "        # print a summary of the whole model\n",
        "        self.model.summary()\n",
        "\n",
        "    def custom_loss(self, y_true, y_pred):\n",
        "        mask_shape = tf.shape(y_true)[:4]\n",
        "        \n",
        "        cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(self.grid_w), [self.grid_h]), (1, self.grid_h, self.grid_w, 1, 1)))\n",
        "        cell_y = tf.transpose(cell_x, (0,2,1,3,4))\n",
        "\n",
        "        cell_grid = tf.tile(tf.concat([cell_x,cell_y], -1), [self.batch_size, 1, 1, self.nb_box, 1])\n",
        "        \n",
        "        coord_mask = tf.zeros(mask_shape)\n",
        "        conf_mask  = tf.zeros(mask_shape)\n",
        "        class_mask = tf.zeros(mask_shape)\n",
        "        \n",
        "        seen = tf.Variable(0.)\n",
        "        total_recall = tf.Variable(0.)\n",
        "        \n",
        "        \"\"\"\n",
        "        Adjust prediction\n",
        "        \"\"\"\n",
        "        ### adjust x and y      \n",
        "        pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid\n",
        "        \n",
        "        ### adjust w and h\n",
        "        pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(self.anchors, [1,1,1,self.nb_box,2])\n",
        "        \n",
        "        ### adjust confidence\n",
        "        pred_box_conf = tf.sigmoid(y_pred[..., 4])\n",
        "        \n",
        "        ### adjust class probabilities\n",
        "        pred_box_class = y_pred[..., 5:]\n",
        "        \n",
        "        \"\"\"\n",
        "        Adjust ground truth\n",
        "        \"\"\"\n",
        "        ### adjust x and y\n",
        "        true_box_xy = y_true[..., 0:2] # relative position to the containing cell\n",
        "        \n",
        "        ### adjust w and h\n",
        "        true_box_wh = y_true[..., 2:4] # number of cells accross, horizontally and vertically\n",
        "        \n",
        "        ### adjust confidence\n",
        "        true_wh_half = true_box_wh / 2.\n",
        "        true_mins    = true_box_xy - true_wh_half\n",
        "        true_maxes   = true_box_xy + true_wh_half\n",
        "        \n",
        "        pred_wh_half = pred_box_wh / 2.\n",
        "        pred_mins    = pred_box_xy - pred_wh_half\n",
        "        pred_maxes   = pred_box_xy + pred_wh_half       \n",
        "        \n",
        "        intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "        intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "        intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "        intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "        \n",
        "        true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
        "        pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
        "\n",
        "        union_areas = pred_areas + true_areas - intersect_areas\n",
        "        iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
        "        \n",
        "        true_box_conf = iou_scores * y_true[..., 4]\n",
        "        \n",
        "        ### adjust class probabilities\n",
        "        true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
        "        \n",
        "        \"\"\"\n",
        "        Determine the masks\n",
        "        \"\"\"\n",
        "        ### coordinate mask: simply the position of the ground truth boxes (the predictors)\n",
        "        coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * self.coord_scale\n",
        "        \n",
        "        ### confidence mask: penelize predictors + penalize boxes with low IOU\n",
        "        # penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
        "        true_xy = self.true_boxes[..., 0:2]\n",
        "        true_wh = self.true_boxes[..., 2:4]\n",
        "        \n",
        "        true_wh_half = true_wh / 2.\n",
        "        true_mins    = true_xy - true_wh_half\n",
        "        true_maxes   = true_xy + true_wh_half\n",
        "        \n",
        "        pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
        "        pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
        "        \n",
        "        pred_wh_half = pred_wh / 2.\n",
        "        pred_mins    = pred_xy - pred_wh_half\n",
        "        pred_maxes   = pred_xy + pred_wh_half    \n",
        "        \n",
        "        intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "        intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "        intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "        intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "        \n",
        "        true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
        "        pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
        "\n",
        "        union_areas = pred_areas + true_areas - intersect_areas\n",
        "        iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
        "\n",
        "        best_ious = tf.reduce_max(iou_scores, axis=4)\n",
        "        conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * self.no_object_scale\n",
        "        \n",
        "        # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
        "        conf_mask = conf_mask + y_true[..., 4] * self.object_scale\n",
        "        \n",
        "        ### class mask: simply the position of the ground truth boxes (the predictors)\n",
        "        class_mask = y_true[..., 4] * tf.gather(self.class_wt, true_box_class) * self.class_scale       \n",
        "        \n",
        "        \"\"\"\n",
        "        Warm-up training\n",
        "        \"\"\"\n",
        "        no_boxes_mask = tf.to_float(coord_mask < self.coord_scale/2.)\n",
        "        seen = tf.assign_add(seen, 1.)\n",
        "        \n",
        "        true_box_xy, true_box_wh, coord_mask = tf.cond(tf.less(seen, self.warmup_batches+1), \n",
        "                              lambda: [true_box_xy + (0.5 + cell_grid) * no_boxes_mask, \n",
        "                                       true_box_wh + tf.ones_like(true_box_wh) * \\\n",
        "                                       np.reshape(self.anchors, [1,1,1,self.nb_box,2]) * \\\n",
        "                                       no_boxes_mask, \n",
        "                                       tf.ones_like(coord_mask)],\n",
        "                              lambda: [true_box_xy, \n",
        "                                       true_box_wh,\n",
        "                                       coord_mask])\n",
        "        \n",
        "        \"\"\"\n",
        "        Finalize the loss\n",
        "        \"\"\"\n",
        "        nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
        "        nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
        "        nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
        "        \n",
        "        loss_xy    = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "        loss_wh    = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
        "        loss_conf  = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
        "        loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
        "        loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
        "        \n",
        "        loss = tf.cond(tf.less(seen, self.warmup_batches+1), \n",
        "                      lambda: loss_xy + loss_wh + loss_conf + loss_class + 10,\n",
        "                      lambda: loss_xy + loss_wh + loss_conf + loss_class)\n",
        "        \n",
        "        if self.debug:\n",
        "            nb_true_box = tf.reduce_sum(y_true[..., 4])\n",
        "            nb_pred_box = tf.reduce_sum(tf.to_float(true_box_conf > 0.5) * tf.to_float(pred_box_conf > 0.3))\n",
        "            \n",
        "            current_recall = nb_pred_box/(nb_true_box + 1e-6)\n",
        "            total_recall = tf.assign_add(total_recall, current_recall) \n",
        "\n",
        "            loss = tf.Print(loss, [loss_xy], message='Loss XY \\t', summarize=1000)\n",
        "            loss = tf.Print(loss, [loss_wh], message='Loss WH \\t', summarize=1000)\n",
        "            loss = tf.Print(loss, [loss_conf], message='Loss Conf \\t', summarize=1000)\n",
        "            loss = tf.Print(loss, [loss_class], message='Loss Class \\t', summarize=1000)\n",
        "            loss = tf.Print(loss, [loss], message='Total Loss \\t', summarize=1000)\n",
        "            loss = tf.Print(loss, [current_recall], message='Current Recall \\t', summarize=1000)\n",
        "            loss = tf.Print(loss, [total_recall/seen], message='Average Recall \\t', summarize=1000)\n",
        "        \n",
        "        return loss\n",
        "\n",
        "    def load_weights(self, weight_path):\n",
        "        self.model.load_weights(weight_path)\n",
        "\n",
        "    def train(self, train_imgs,     # the list of images to train the model\n",
        "                    valid_imgs,     # the list of images used to validate the model\n",
        "                    train_times,    # the number of time to repeat the training set, often used for small datasets\n",
        "                    valid_times,    # the number of times to repeat the validation set, often used for small datasets\n",
        "                    nb_epochs,      # number of epoches\n",
        "                    learning_rate,  # the learning rate\n",
        "                    batch_size,     # the size of the batch\n",
        "                    warmup_epochs,  # number of initial batches to let the model familiarize with the new dataset\n",
        "                    object_scale,\n",
        "                    no_object_scale,\n",
        "                    coord_scale,\n",
        "                    class_scale,\n",
        "                    saved_weights_name='best_weights.h5',\n",
        "                    debug=False):     \n",
        "\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.object_scale    = object_scale\n",
        "        self.no_object_scale = no_object_scale\n",
        "        self.coord_scale     = coord_scale\n",
        "        self.class_scale     = class_scale\n",
        "\n",
        "        self.debug = debug\n",
        "\n",
        "        ############################################\n",
        "        # Make train and validation generators\n",
        "        ############################################\n",
        "\n",
        "        generator_config = {\n",
        "            'IMAGE_H'         : self.input_size, \n",
        "            'IMAGE_W'         : self.input_size,\n",
        "            'GRID_H'          : self.grid_h,  \n",
        "            'GRID_W'          : self.grid_w,\n",
        "            'BOX'             : self.nb_box,\n",
        "            'LABELS'          : self.labels,\n",
        "            'CLASS'           : len(self.labels),\n",
        "            'ANCHORS'         : self.anchors,\n",
        "            'BATCH_SIZE'      : self.batch_size,\n",
        "            'TRUE_BOX_BUFFER' : self.max_box_per_image,\n",
        "        }    \n",
        "\n",
        "        train_generator = BatchGenerator(train_imgs, \n",
        "                                     generator_config, \n",
        "                                     norm=self.feature_extractor.normalize)\n",
        "        valid_generator = BatchGenerator(valid_imgs, \n",
        "                                     generator_config, \n",
        "                                     norm=self.feature_extractor.normalize,\n",
        "                                     jitter=False)   \n",
        "                                     \n",
        "        self.warmup_batches  = warmup_epochs * (train_times*len(train_generator) + valid_times*len(valid_generator))   \n",
        "\n",
        "        ############################################\n",
        "        # Compile the model\n",
        "        ############################################\n",
        "\n",
        "        optimizer = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "        self.model.compile(loss=self.custom_loss, optimizer=optimizer)\n",
        "\n",
        "        ############################################\n",
        "        # Make a few callbacks\n",
        "        ############################################\n",
        "\n",
        "        early_stop = EarlyStopping(monitor='val_loss', \n",
        "                           min_delta=0.001, \n",
        "                           patience=3, \n",
        "                           mode='min', \n",
        "                           verbose=1)\n",
        "        checkpoint = ModelCheckpoint(saved_weights_name, \n",
        "                                     monitor='val_loss', \n",
        "                                     verbose=1, \n",
        "                                     save_best_only=True, \n",
        "                                     mode='min', \n",
        "                                     period=1)\n",
        "        tensorboard = TensorBoard(log_dir=os.path.expanduser('~/logs/'), \n",
        "                                  histogram_freq=0, \n",
        "                                  #write_batch_performance=True,\n",
        "                                  write_graph=True, \n",
        "                                  write_images=False)\n",
        "\n",
        "        ############################################\n",
        "        # Start the training process\n",
        "        ############################################        \n",
        "\n",
        "        self.model.fit_generator(generator        = train_generator, \n",
        "                                 steps_per_epoch  = len(train_generator) * train_times, \n",
        "                                 epochs           = warmup_epochs + nb_epochs, \n",
        "                                 verbose          = 2 if debug else 1,\n",
        "                                 validation_data  = valid_generator,\n",
        "                                 validation_steps = len(valid_generator) * valid_times,\n",
        "                                 callbacks        = [early_stop, checkpoint, tensorboard], \n",
        "                                 workers          = 3,\n",
        "                                 max_queue_size   = 8)      \n",
        "\n",
        "        ############################################\n",
        "        # Compute mAP on the validation set\n",
        "        ############################################\n",
        "        average_precisions = self.evaluate(valid_generator)     \n",
        "\n",
        "        # print evaluation\n",
        "        for label, average_precision in average_precisions.items():\n",
        "            print(self.labels[label], '{:.4f}'.format(average_precision))\n",
        "        print('mAP: {:.4f}'.format(sum(average_precisions.values()) / len(average_precisions)))         \n",
        "\n",
        "    def evaluate(self, \n",
        "                 generator, \n",
        "                 iou_threshold=0.3,\n",
        "                 score_threshold=0.3,\n",
        "                 max_detections=100,\n",
        "                 save_path=None):\n",
        "        \"\"\" Evaluate a given dataset using a given model.\n",
        "        code originally from https://github.com/fizyr/keras-retinanet\n",
        "\n",
        "        # Arguments\n",
        "            generator       : The generator that represents the dataset to evaluate.\n",
        "            model           : The model to evaluate.\n",
        "            iou_threshold   : The threshold used to consider when a detection is positive or negative.\n",
        "            score_threshold : The score confidence threshold to use for detections.\n",
        "            max_detections  : The maximum number of detections to use per image.\n",
        "            save_path       : The path to save images with visualized detections to.\n",
        "        # Returns\n",
        "            A dict mapping class names to mAP scores.\n",
        "        \"\"\"    \n",
        "        # gather all detections and annotations\n",
        "        all_detections     = [[None for i in range(generator.num_classes())] for j in range(generator.size())]\n",
        "        all_annotations    = [[None for i in range(generator.num_classes())] for j in range(generator.size())]\n",
        "\n",
        "        for i in range(generator.size()):\n",
        "            raw_image = generator.load_image(i)\n",
        "            raw_height, raw_width, raw_channels = raw_image.shape\n",
        "\n",
        "            # make the boxes and the labels\n",
        "            pred_boxes  = self.predict(raw_image)\n",
        "\n",
        "            \n",
        "            score = np.array([box.score for box in pred_boxes])\n",
        "            pred_labels = np.array([box.label for box in pred_boxes])        \n",
        "            \n",
        "            if len(pred_boxes) > 0:\n",
        "                pred_boxes = np.array([[box.xmin*raw_width, box.ymin*raw_height, box.xmax*raw_width, box.ymax*raw_height, box.score] for box in pred_boxes])\n",
        "            else:\n",
        "                pred_boxes = np.array([[]])  \n",
        "            \n",
        "            # sort the boxes and the labels according to scores\n",
        "            score_sort = np.argsort(-score)\n",
        "            pred_labels = pred_labels[score_sort]\n",
        "            pred_boxes  = pred_boxes[score_sort]\n",
        "            \n",
        "            # copy detections to all_detections\n",
        "            for label in range(generator.num_classes()):\n",
        "                all_detections[i][label] = pred_boxes[pred_labels == label, :]\n",
        "                \n",
        "            annotations = generator.load_annotation(i)\n",
        "            \n",
        "            # copy detections to all_annotations\n",
        "            for label in range(generator.num_classes()):\n",
        "                all_annotations[i][label] = annotations[annotations[:, 4] == label, :4].copy()\n",
        "                \n",
        "        # compute mAP by comparing all detections and all annotations\n",
        "        average_precisions = {}\n",
        "        \n",
        "        for label in range(generator.num_classes()):\n",
        "            false_positives = np.zeros((0,))\n",
        "            true_positives  = np.zeros((0,))\n",
        "            scores          = np.zeros((0,))\n",
        "            num_annotations = 0.0\n",
        "\n",
        "            for i in range(generator.size()):\n",
        "                detections           = all_detections[i][label]\n",
        "                annotations          = all_annotations[i][label]\n",
        "                num_annotations     += annotations.shape[0]\n",
        "                detected_annotations = []\n",
        "\n",
        "                for d in detections:\n",
        "                    scores = np.append(scores, d[4])\n",
        "\n",
        "                    if annotations.shape[0] == 0:\n",
        "                        false_positives = np.append(false_positives, 1)\n",
        "                        true_positives  = np.append(true_positives, 0)\n",
        "                        continue\n",
        "\n",
        "                    overlaps            = compute_overlap(np.expand_dims(d, axis=0), annotations)\n",
        "                    assigned_annotation = np.argmax(overlaps, axis=1)\n",
        "                    max_overlap         = overlaps[0, assigned_annotation]\n",
        "\n",
        "                    if max_overlap >= iou_threshold and assigned_annotation not in detected_annotations:\n",
        "                        false_positives = np.append(false_positives, 0)\n",
        "                        true_positives  = np.append(true_positives, 1)\n",
        "                        detected_annotations.append(assigned_annotation)\n",
        "                    else:\n",
        "                        false_positives = np.append(false_positives, 1)\n",
        "                        true_positives  = np.append(true_positives, 0)\n",
        "\n",
        "            # no annotations -> AP for this class is 0 (is this correct?)\n",
        "            if num_annotations == 0:\n",
        "                average_precisions[label] = 0\n",
        "                continue\n",
        "\n",
        "            # sort by score\n",
        "            indices         = np.argsort(-scores)\n",
        "            false_positives = false_positives[indices]\n",
        "            true_positives  = true_positives[indices]\n",
        "\n",
        "            # compute false positives and true positives\n",
        "            false_positives = np.cumsum(false_positives)\n",
        "            true_positives  = np.cumsum(true_positives)\n",
        "\n",
        "            # compute recall and precision\n",
        "            recall    = true_positives / num_annotations\n",
        "            precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
        "\n",
        "            # compute average precision\n",
        "            average_precision  = compute_ap(recall, precision)  \n",
        "            average_precisions[label] = average_precision\n",
        "\n",
        "        return average_precisions    \n",
        "\n",
        "    def predict(self, image):\n",
        "        image_h, image_w, _ = image.shape\n",
        "        image = cv2.resize(image, (self.input_size, self.input_size))\n",
        "        image = self.feature_extractor.normalize(image)\n",
        "\n",
        "        input_image = image[:,:,::-1]\n",
        "        input_image = np.expand_dims(input_image, 0)\n",
        "        dummy_array = np.zeros((1,1,1,1,self.max_box_per_image,4))\n",
        "\n",
        "        netout = self.model.predict([input_image, dummy_array])[0]\n",
        "        boxes  = decode_netout(netout, self.anchors, self.nb_class)\n",
        "\n",
        "        return boxes"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgVxdMRCmFcn",
        "outputId": "dfc09d8e-1f78-4bd9-8301-4889eb578799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "###################\n",
        "#Part B/1. Frozen graph (freeze tensor flow model)\n",
        "###################\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import json\n",
        "\n",
        "\n",
        "#Jordan_note: Getting the failedpreconditionerror, I followed user \"user3144836\"'s response, where I decided to encapsulate the entire code block nder the with routine he suggested.\n",
        "#this removed error.\n",
        "#https://stackoverflow.com/a/41607207/7183973 \n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
        "        \"\"\"\n",
        "        Freezes the state of a session into a pruned computation graph.\n",
        "\n",
        "        Creates a new computation graph where variable nodes are replaced by\n",
        "        constants taking their current value in the session. The new graph will be\n",
        "        pruned so subgraphs that are not necessary to compute the requested\n",
        "        outputs are removed.\n",
        "        @param session The TensorFlow session to be frozen.\n",
        "        @param keep_var_names A list of variable names that should not be frozen,\n",
        "                              or None to freeze all the variables in the graph.\n",
        "        @param output_names Names of the relevant graph outputs.\n",
        "        @param clear_devices Remove the device directives from the graph for better portability.\n",
        "        @return The frozen graph definition.\n",
        "        \"\"\"\n",
        "        graph = session.graph\n",
        "        with graph.as_default():\n",
        "            freeze_var_names = list(set(v.op.name for v in tf.compat.v1.global_variables()).difference(keep_var_names or []))\n",
        "            output_names = output_names or []\n",
        "            output_names += [v.op.name for v in tf.compat.v1.global_variables()]\n",
        "            input_graph_def = graph.as_graph_def()\n",
        "            if clear_devices:\n",
        "                for node in input_graph_def.node:\n",
        "                    node.device = ''\n",
        "            frozen_graph = tf.graph_util.convert_variables_to_constants(\n",
        "                session, input_graph_def, output_names, freeze_var_names)\n",
        "            return frozen_graph\n",
        "          \n",
        "    #load trained weights and config file from google drive account\n",
        "    jordan_drive_trained_weights_id = '10Ymwx7BCYye6hZHewS1FctgENEk3R7V1';\n",
        "\n",
        "    file_obj_trained_weights = drive.CreateFile({'id': jordan_drive_trained_weights_id})                       \n",
        "\n",
        "    file_obj_trained_weights.GetContentFile ( \"trained_wts.h5\" )\n",
        "\n",
        "\n",
        "    jordan_drive_trained_weights_CONFIG_id = \"1Qny9it02xW-v2Kbys3tgPLaMNftAibCC\"\n",
        "\n",
        "    file_obj_trained_weights_config = drive.CreateFile({'id': jordan_drive_trained_weights_CONFIG_id})   \n",
        "\n",
        "    file_obj_trained_weights_config.GetContentFile ( \"config.json\" )\n",
        "\n",
        "\n",
        "    config_path  = 'config.json'\n",
        "    weights_path = 'trained_wts.h5'\n",
        "\n",
        "    with open(config_path) as config_buffer:    \n",
        "        config = json.load(config_buffer)\n",
        "        \n",
        "    yolo = YOLO(backend            = config['model']['backend'],\n",
        "                input_size          = config['model']['input_size'], \n",
        "                labels              = config['model']['labels'], \n",
        "                max_box_per_image   = config['model']['max_box_per_image'],\n",
        "                anchors             = config['model']['anchors'])\n",
        "    \n",
        "\n",
        "    ###############################\n",
        "    #   Load trained weights\n",
        "    ###############################\n",
        "\n",
        "    ## dir(model.model) reveals native keras model attributes. Jordan tried .model by curiousity :)\n",
        "\n",
        "    yolo.load_weights(weights_path)\n",
        "    \n",
        "    model = yolo.model\n",
        "    \n",
        "    input_names = [i.op.name for i in model.inputs]\n",
        "    output_names_ = [o.op.name for o in model.outputs]\n",
        "\n",
        "    # inputs:  ['input_1', 'input_2']\n",
        "    print('inputs: ', input_names)\n",
        "\n",
        "    # outputs: ['lambda_2/Identity']\n",
        "    print('outputs: ', output_names_)\n",
        "    \n",
        "    frozen_graph = freeze_session(tf.compat.v1.keras.backend.get_session(), output_names=output_names_)\n",
        "    print (\"frozen_graph composed successfully.\")\n",
        "    \n",
        "    #tf.io.write_graph(frozen_graph, './', 'pothole_detector.pbtxt', as_text=True)\n",
        "    #tf.io.write_graph(frozen_graph, './', 'pothole_detector.pb', as_text=False)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-ce8d9a113c2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#this removed error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#https://stackoverflow.com/a/41607207/7183973\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWygvIyctpeI"
      },
      "source": [
        "###################\n",
        "#Part B/2a. Convert frozen graph 32bit (fp32) to tensorrt graph 16 bit (fp16)\n",
        "###################\n",
        "\n",
        "import tensorflow.contrib.tensorrt as trt\n",
        "from tensorflow.python.framework import graph_io\n",
        "\n",
        "trt_graph = trt.create_inference_graph(\n",
        "    input_graph_def=frozen_graph,\n",
        "    outputs=output_names_,\n",
        "    max_batch_size=1,\n",
        "    max_workspace_size_bytes=1 << 25,\n",
        "    precision_mode='FP16',\n",
        "    minimum_segment_size=50\n",
        ")\n",
        "\n",
        "graph_io.write_graph(trt_graph, \"\",\n",
        "                     \"trt_pothole_graph.pb\", as_text=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGqN3UXquW-m"
      },
      "source": [
        "#Part B/2b/Alternative, quickly reference trt graph stored in my google drive. (Instead of regenerating the same trt graph in colab)\n",
        "#This is a file in Jordan's google drive. \n",
        "trt_graph_jordan_drive_id = '1b9XgpXeWBay6GE2bnLSqlLSXDEFfUCZd';\n",
        "trt_graph_jordan_drive_file = drive.CreateFile({'id': trt_graph_jordan_drive_id})                       \n",
        "trt_graph_jordan_drive_file.GetContentFile ( \"trt_pothole_graph.pb\" ) #allows colab to access network sample prediction"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-Jx1Yq0uejv",
        "outputId": "40f63685-e87d-4bce-c3ac-55e147641b97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "###################\n",
        "#Part B/3a. Load tensor RT fp16 graph\n",
        "###################\n",
        "import tensorflow.compat.v1 as tf #Jordan_note: Resolves  module 'tensorflow' has no attribute 'gfile' error, since Collab seems to have updated these.\n",
        "\n",
        "\n",
        "#jordan_declaration: input and output names taken from frozen graph generation process\n",
        "#this is to avoid re-running frozen graph generation on jetson nano, instead okay to use generatred frozen graph file on storage.\n",
        "input_names =  ['input_1', 'input_2']\n",
        "output_names_ = ['lambda_2/Identity']\n",
        "\n",
        "def get_frozen_graph(graph_file):\n",
        "    \"\"\"Read Frozen Graph file from disk.\"\"\"\n",
        "    with tf.gfile.FastGFile(graph_file, \"rb\") as f:\n",
        "        graph_def = tf.GraphDef()\n",
        "        graph_def.ParseFromString(f.read())\n",
        "    return graph_def\n",
        "\n",
        "\n",
        "#trt_graph = get_frozen_graph('pothole_model_tensor_rt_format/trt_pothole_graph.pb') #reads from colab directory\n",
        "trt_graph = get_frozen_graph('trt_pothole_graph.pb') #reads from google drive\n",
        "\n",
        "# Create session and load graph\n",
        "tf_config = tf.ConfigProto()\n",
        "tf_config.gpu_options.allow_growth = True\n",
        "tf_sess = tf.Session(config=tf_config)\n",
        "tf.import_graph_def(trt_graph, name='')\n",
        "\n",
        "\n",
        "# Get graph input size\n",
        "for node in trt_graph.node:\n",
        "    if 'input_' in node.name:\n",
        "        size = node.attr['shape'].shape\n",
        "        image_size = [size.dim[i].size for i in range(1, 4)]\n",
        "        break\n",
        "print(\"image_size: {}\".format(image_size))\n",
        "\n",
        "\n",
        "# input and output tensor names.\n",
        "input_tensor_name = input_names[0] + \":0\"\n",
        "output_tensor_name = output_names_[0] + \":0\"\n",
        "\n",
        "print(\"input_tensor_name: {}\\noutput_tensor_name: {}\".format(\n",
        "    input_tensor_name, output_tensor_name))\n",
        "\n",
        "with tf.Session() as sess: #jordan_node added these two lines to resolve FailedPreconditionError, that happens in Part B/4 prediciton on runtime.\n",
        "  tf_sess.run(tf.global_variables_initializer())\n",
        "\n",
        "output_tensor = tf_sess.graph.get_tensor_by_name(output_tensor_name)\n",
        "\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-22-bd597d697103>:14: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.gfile.GFile.\n",
            "image_size: [416, 416, 3]\n",
            "input_tensor_name: input_1:0\n",
            "output_tensor_name: lambda_2/Identity:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azhh5OA2vI72"
      },
      "source": [
        "###################\n",
        "#Part B/3b. Ready-made decoder to decode pothole neural network output from 5D array, to simple outcome.\n",
        "#Note by Jordan: I took this from original desktop-version pothole code. I took relevant params to decode_netout from the config file of said repository.\n",
        "#The only param that is dynamic here is the neural network hypothesis/output=\"netout\".\n",
        "###################\n",
        "import numpy as np\n",
        "\n",
        "anchors__=[0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
        "obj_threshold__=0.3\n",
        "nms_threshold__=0.3\n",
        "nb_class__=1 #where 1 is equivalent to the number of labels of this neural network, i.e. only \"pothole\"\n",
        "\n",
        "  \n",
        "def decode_hypothesis(netout, anchors=anchors__, nb_class=nb_class__, obj_threshold=obj_threshold__, nms_threshold=nms_threshold__):\n",
        "    grid_h, grid_w, nb_box = netout.shape[:3]\n",
        "\n",
        "    boxes = []\n",
        "    \n",
        "    # decode the output by the network\n",
        "    netout[..., 4]  = _sigmoid(netout[..., 4])\n",
        "    netout[..., 5:] = netout[..., 4][..., np.newaxis] * _softmax(netout[..., 5:])\n",
        "    netout[..., 5:] *= netout[..., 5:] > obj_threshold\n",
        "    \n",
        "    for row in range(grid_h):\n",
        "        for col in range(grid_w):\n",
        "            for b in range(nb_box):\n",
        "                # from 4th element onwards are confidence and class classes\n",
        "                classes = netout[row,col,b,5:]\n",
        "                \n",
        "                if np.sum(classes) > 0:\n",
        "                    # first 4 elements are x, y, w, and h\n",
        "                    x, y, w, h = netout[row,col,b,:4]\n",
        "\n",
        "                    x = (col + _sigmoid(x)) / grid_w # center position, unit: image width\n",
        "                    y = (row + _sigmoid(y)) / grid_h # center position, unit: image height\n",
        "                    w = anchors[2 * b + 0] * np.exp(w) / grid_w # unit: image width\n",
        "                    h = anchors[2 * b + 1] * np.exp(h) / grid_h # unit: image height\n",
        "                    confidence = netout[row,col,b,4]\n",
        "                    \n",
        "                    box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, confidence, classes)\n",
        "                    \n",
        "                    boxes.append(box)\n",
        "\n",
        "    # suppress non-maximal boxes\n",
        "    for c in range(nb_class):\n",
        "        sorted_indices = list(reversed(np.argsort([box.classes[c] for box in boxes])))\n",
        "\n",
        "        for i in range(len(sorted_indices)):\n",
        "            index_i = sorted_indices[i]\n",
        "            \n",
        "            if boxes[index_i].classes[c] == 0: \n",
        "                continue\n",
        "            else:\n",
        "                for j in range(i+1, len(sorted_indices)):\n",
        "                    index_j = sorted_indices[j]\n",
        "                    \n",
        "                    if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_threshold:\n",
        "                        boxes[index_j].classes[c] = 0\n",
        "                        \n",
        "    # remove the boxes which are less likely than a obj_threshold\n",
        "    boxes = [box for box in boxes if box.get_score() > obj_threshold]\n",
        "    \n",
        "    return boxes "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrHyjN_Cvk4Z",
        "outputId": "38f57431-3972-4d1d-b8fa-ff8b9bf984ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "###################\n",
        "#Written by Jordan Bennett\n",
        "#Part B/4. Make predictions based on FP16 graph. \n",
        "###################\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "\n",
        "#This is a file in Jordan's google drive. \n",
        "jordan_drive_pothole_sample_0_id = '1GIt_daWwyrjV7-pibonwCv-G8Gks3KHR';\n",
        "file_obj_pothole_sample_0 = drive.CreateFile({'id': jordan_drive_pothole_sample_0_id})                       \n",
        "file_obj_pothole_sample_0.GetContentFile ( \"pothole_sample_0.jpg\" ) #allows colab to access pothole image (1 pothole)\n",
        "\n",
        "#This is a file in Jordan's google drive. \n",
        "jordan_drive_pothole_sample_1_id = '1YVknsYymTdMGLLLdqewOse9LKhieSU6R';\n",
        "file_obj_pothole_sample_1 = drive.CreateFile({'id': jordan_drive_pothole_sample_1_id})                       \n",
        "file_obj_pothole_sample_1.GetContentFile ( \"pothole_sample_1.jpg\" ) #allows colab to access pothole image (3 potholes)\n",
        "\n",
        "\n",
        "#This is a file in Jordan's google drive. \n",
        "jordan_drive_pothole_sample_2_id = '18EBtBP3b6wfPyk03bGJYN_DHCKbSe6eX';\n",
        "file_obj_pothole_sample_2 = drive.CreateFile({'id': jordan_drive_pothole_sample_2_id})                       \n",
        "file_obj_pothole_sample_2.GetContentFile ( \"pothole_sample_2.jpg\" ) #allows colab to access pothole image (8 potholes)\n",
        "\n",
        "#This is a file in Jordan's google drive. \n",
        "jordan_drive_pothole_negative_sample_0_id = '1_ik0jpPiulsdkYYRtIbhcRlULVNSUeIe';\n",
        "file_obj_pothole_negative_sample_0 = drive.CreateFile({'id': jordan_drive_pothole_negative_sample_0_id})                       \n",
        "file_obj_pothole_negative_sample_0.GetContentFile ( \"pothole_negative_sample.jpg\" ) #allows colab to access pothole negative image (no potholes)\n",
        "\n",
        "\n",
        "def getPrediction (image_path__):\n",
        "  img = image.load_img(image_path__, target_size=image_size[:2]) #where image_size[:2] = \"[416,416,3]\", which corresponds somewhat to config[\"input_size\"] in config.json.\n",
        "  \n",
        "  x = image.img_to_array(img)/255.0 #CRUCIAL!!!-->jordan_normalize IMAGE_DATA=image.img_to_array(...) as seen in desktop version. Otherwise image data contains large integers, which is not expected by the trained pothole model which expects small normalized floating point values.\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  feed_dict = {\n",
        "      input_tensor_name: x\n",
        "  }\n",
        "  \n",
        "  hypothesis = tf_sess.run(output_tensor, feed_dict) \n",
        "\n",
        "  hypothesis = hypothesis.reshape ( 13, 13, 5, 6 ) #jordan_addition: correct network output shape based on observation of desktop output analysis\n",
        "\n",
        "  \n",
        "  #jordan_note: The output of the neural network is a bunch of pixels, or bounding boxes. Cardinality of those boxes equals pothole cardinality.\n",
        "  print('Caution!', len(decode_hypothesis(hypothesis)), 'pothole(s) are detected ahead from input image: ', image_path__ )\n",
        "\n",
        "########################################################   \n",
        "########################################################   \n",
        "#####Test on image sample 0, with 1 potholes\n",
        "getPrediction ('pothole_sample_0.jpg')\n",
        "#####Test on image sample 1, with 3 potholes\n",
        "getPrediction ('pothole_sample_1.jpg')\n",
        "#####Test on image sample 2, with 8 potholes\n",
        "getPrediction ('pothole_sample_2.jpg')\n",
        "#####Test on image sample 3, with 0 potholes\n",
        "getPrediction ('pothole_negative_sample.jpg')\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "###############################################\n",
        "#Runtime cost test. Test speed of prediction on optimized tensor rt graph \n",
        "#this same code is ran in Desktop version, which yielded (except for getPrediction which is swapped with desktop equivalent)\n",
        "print(\"\\n\\n########\\nExecution runtime cost test\")\n",
        "import time\n",
        "times = []\n",
        "for i in range(20):\n",
        "    start_time = time.time()\n",
        "    getPrediction ('pothole_sample_2.jpg')\n",
        "    delta = (time.time() - start_time)\n",
        "    times.append(delta)\n",
        "mean_delta = np.array(times).mean()\n",
        "fps = 1 / mean_delta\n",
        "print('average(sec):{:.2f},fps:{:.2f}'.format(mean_delta, fps))\n",
        "\"\"\""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Caution! 1 pothole(s) are detected ahead from input image:  pothole_sample_0.jpg\n",
            "Caution! 3 pothole(s) are detected ahead from input image:  pothole_sample_1.jpg\n",
            "Caution! 8 pothole(s) are detected ahead from input image:  pothole_sample_2.jpg\n",
            "Caution! 0 pothole(s) are detected ahead from input image:  pothole_negative_sample.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n###############################################\\n#Runtime cost test. Test speed of prediction on optimized tensor rt graph \\n#this same code is ran in Desktop version, which yielded (except for getPrediction which is swapped with desktop equivalent)\\nprint(\"\\n\\n########\\nExecution runtime cost test\")\\nimport time\\ntimes = []\\nfor i in range(20):\\n    start_time = time.time()\\n    getPrediction (\\'pothole_sample_2.jpg\\')\\n    delta = (time.time() - start_time)\\n    times.append(delta)\\nmean_delta = np.array(times).mean()\\nfps = 1 / mean_delta\\nprint(\\'average(sec):{:.2f},fps:{:.2f}\\'.format(mean_delta, fps))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}